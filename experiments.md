# RoBERTa-large

### Evaluation (Pre-Finetune)
```
Test Accuracy: 0.095033
Test F1 Score: 0.086786
```

### Finetuning (10 Epochs)
```
17:27:15 - num_epochs = 10 | lr = 2e-05 | patience = 2
17:31:18 - Epoch 1/10 | Train Loss: 0.307378 | Validation Loss: 0.215937
17:35:23 - Epoch 2/10 | Train Loss: 0.209410 | Validation Loss: 0.122734
17:39:28 - Epoch 3/10 | Train Loss: 0.141320 | Validation Loss: 0.069844
17:43:32 - Epoch 4/10 | Train Loss: 0.071849 | Validation Loss: 0.014653
17:47:37 - Epoch 5/10 | Train Loss: 0.032062 | Validation Loss: 0.010461
17:51:42 - Epoch 6/10 | Train Loss: 0.019765 | Validation Loss: 0.005185
17:55:47 - Epoch 7/10 | Train Loss: 0.010363 | Validation Loss: 0.002446
17:59:52 - Epoch 8/10 | Train Loss: 0.004966 | Validation Loss: 0.000759
18:03:57 - Epoch 9/10 | Train Loss: 0.002219 | Validation Loss: 0.000318
18:08:02 - Epoch 10/10 | Train Loss: 0.001054 | Validation Loss: 0.000296
```

### Evaluation (Post-Finetune)
```
Test Accuracy: 0.923591
Test F1 Score: 0.754404
```